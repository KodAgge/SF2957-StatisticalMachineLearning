{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97dab2e-d810-4bdf-9aa1-78c97a7a3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "\n",
    "# import some data to play with\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "\n",
    "#choose a seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "# Load data into train set and test set\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = np.array(digits.target, dtype = int)\n",
    "X,y = shuffle(X,y)\n",
    "\n",
    "\n",
    "def svmsubgradient(Theta, x, y):\n",
    "#  Returns a subgradient of the objective empirical hinge loss\n",
    "#\n",
    "# The inputs are Theta, of size n-by-K, where K is the number of classes,\n",
    "# x of size n, and y an integer in {0, 1, ..., 9}.\n",
    "    G = np.zeros(Theta.shape)\n",
    "    ## IMPLEMENT THE SUBGRADIENT CALCULATION -- YOUR CODE HERE\n",
    "    K = Theta.shape[1]\n",
    "    x.shape = d,1 \n",
    "    for j in range(K):\n",
    "        if y != j:\n",
    "            indices = list(range(K))\n",
    "            indices.remove(j)\n",
    "            indices.remove(y)\n",
    "            if 1+np.dot(x.T, Theta[:,[j]]-Theta[:,[y]])>np.max(1+np.matmul(x.T, Theta[:,indices]-np.tile(Theta[:,[y]],(1,8))), axis=1):\n",
    "                G[:,[j]] = x\n",
    "            # Else zero\n",
    "        else:\n",
    "            indices = list(range(K))\n",
    "            indices.remove(y)\n",
    "            if np.max(1+np.matmul(x.T, Theta[:,indices]-np.tile(Theta[:,[y]],(1,9))), axis=1)>0:\n",
    "                G[:,[j]] = -x\n",
    "            # Else zero\n",
    "    \n",
    "    return(G)\n",
    "\n",
    "def sgd(Xtrain, ytrain, maxiter = 10, init_stepsize = 1.0, l2_radius = 10000):\n",
    "#\n",
    "# Performs maxiter iterations of projected stochastic gradient descent\n",
    "# on the data contained in the matrix Xtrain, of size n-by-d, where n\n",
    "# is the sample size and d is the dimension, and the label vector\n",
    "# ytrain of integers in {0, 1, ..., 9}. Returns two d-by-10\n",
    "# classification matrices Theta and mean_Theta, where the first is the final\n",
    "# point of SGD and the second is the mean of all the iterates of SGD.\n",
    "#\n",
    "# Each iteration consists of choosing a random index from n and the\n",
    "# associated data point in X, taking a subgradient step for the\n",
    "# multiclass SVM objective, and projecting onto the Euclidean ball\n",
    "# The stepsize is init_stepsize / sqrt(iteration).\n",
    "    K = 10\n",
    "    NN, dd = Xtrain.shape\n",
    "    Theta = np.zeros(dd*K)\n",
    "    Theta.shape = dd,K\n",
    "    mean_Theta = np.zeros(dd*K)\n",
    "    mean_Theta.shape = dd,K\n",
    "    ## YOUR CODE HERE -- IMPLEMENT PROJECTED STOCHASTIC GRADIENT DESCENT\n",
    "    \n",
    "    for iteration in range(maxiter):\n",
    "        epsilon_k = init_stepsize/np.sqrt(iteration+1)\n",
    "        n = np.random.choice(NN)\n",
    "        x = Xtrain[n,:]\n",
    "        y = ytrain[n]\n",
    "        Theta = Theta - epsilon_k * svmsubgradient(Theta, x, y)\n",
    "        if np.sum(np.square(Theta))>l2_radius**2:\n",
    "            Theta = Theta/np.sum(np.square(Theta))*l2_radius\n",
    "        mean_Theta = (iteration*mean_Theta+Theta)/(iteration+1)\n",
    "    return Theta, mean_Theta\n",
    "\n",
    "def Classify(Xdata, Theta):\n",
    "#\n",
    "# Takes in an N-by-d data matrix Adata, where d is the dimension and N\n",
    "# is the sample size, and a classifier X, which is of size d-by-K,\n",
    "# where K is the number of classes.\n",
    "#\n",
    "# Returns a vector of length N consisting of the predicted digits in\n",
    "# the classes.\n",
    "    scores = np.matmul(Xdata, Theta)\n",
    "    inds = np.argmax(scores, axis = 1)\n",
    "    return(inds)\n",
    "\n",
    "N,d = X.shape\n",
    "def main(trainsize):\n",
    "    N,d = X.shape\n",
    "    Ntest = int(100)\n",
    "    Ntrain = int(trainsize)\n",
    "    M = Ntest + Ntrain\n",
    "    Xtrain = X[0:Ntrain,:]\n",
    "    ytrain = y[0:Ntrain]\n",
    "    Xtest = X[Ntrain:M,:]\n",
    "    ytest = y[Ntrain:M]\n",
    "    l2_radius = 40.0\n",
    "    M_raw = np.sqrt(np.mean(np.sum(np.square(Xtrain))))\n",
    "    init_stepsize = l2_radius/M_raw\n",
    "    maxiter = 40000\n",
    "    Theta, mean_Theta = sgd(Xtrain, ytrain, maxiter, init_stepsize, l2_radius)\n",
    "    print('Error rate')\n",
    "    print(np.sum(np.not_equal(Classify(Xtest, mean_Theta),ytest)/Ntest))\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f44d841-9e40-47e6-a205-d471c3e15ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate\n",
      "0.43000000000000005\n",
      "Error rate\n",
      "0.25\n",
      "Error rate\n",
      "0.15000000000000002\n",
      "Error rate\n",
      "0.05\n",
      "Error rate\n",
      "0.05\n",
      "Error rate\n",
      "0.04\n"
     ]
    }
   ],
   "source": [
    "error_rates = list()\n",
    "for trainsize in [20,50,100,500,1000,1500]:\n",
    "    error_rates.append(main(trainsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13daa94f-2203-4899-93df-83d741169ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
